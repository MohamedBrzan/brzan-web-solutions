export interface BlogPost {
  id: number;
  title: string;
  slug: string;
  excerpt: string;
  content?: string;
  date?: string;
  readTime?: string;
  image: string;
  tags?: string[];
  category?: string;
}

const blogPosts: BlogPost[] = [
  {
    id: 1,
    title:
      "Mastering JWT Authentication in Node.js: Secure Token-Based Strategies with Express, Refresh Tokens",
    slug: "implementing-authentication-with-jwt-in-nodejs",
    excerpt:
      "Learn how to build a robust, secure JWT-based authentication system in Node.js ‚Äî covering access tokens, refresh tokens, middleware, and security best practices for production applications.",
    content:
      "# Mastering JWT Authentication in Node.js: Secure Token-Based Strategies with Express, Refresh Tokens, and Best Practices\n\nJSON Web Tokens (JWT) have become the de facto standard for stateless, token-based authentication in modern web applications. But building a secure, maintainable JWT system in Node.js requires careful attention to token lifecycle, security, and server architecture.\n\nIn this comprehensive guide, you‚Äôll discover how to build a scalable authentication system using **Node.js**, **Express**, **jsonwebtoken**, and advanced token management‚Äîincluding **refresh tokens**, **security best practices**, and middleware strategies.\n\n---\n\n## üîê 1. Why JWT? Token-Based Authentication Explained\n\nJWT offers a stateless mechanism for authentication by embedding user claims inside signed tokens:\n\n- **Compact** and self-contained\n- **Verifiable** using secret or public keys\n- **No need for server-side session storage**\n\n```\nheader.payload.signature\n```\nWhere the payload includes user data, and the signature ensures integrity.\n\n---\n\n## ‚öôÔ∏è 2. Core JWT Setup in Express\n\n```bash\nnpm init -y\nnpm install express jsonwebtoken bcryptjs dotenv\nnpm install --save-dev nodemon\n```\n\n```js\n// server.js\nrequire('dotenv').config();\nconst express = require('express');\nconst app = express();\napp.use(express.json());\napp.use('/api/auth', require('./routes/auth'));\nconst PORT = process.env.PORT || 4000;\napp.listen(PORT, () => console.log(`Server listening on port ${PORT}`));\n```\n\n---\n\n## üìÅ 3. Project Structure for Scalability\n\n```text\njwt-auth/\n‚îú‚îÄ‚îÄ controllers/\n‚îÇ   ‚îî‚îÄ‚îÄ authController.js\n‚îú‚îÄ‚îÄ middleware/\n‚îÇ   ‚îî‚îÄ‚îÄ verifyToken.js\n‚îú‚îÄ‚îÄ routes/\n‚îÇ   ‚îî‚îÄ‚îÄ auth.js\n‚îú‚îÄ‚îÄ models/\n‚îÇ   ‚îî‚îÄ‚îÄ user.js\n‚îú‚îÄ‚îÄ utils/\n‚îÇ   ‚îî‚îÄ‚îÄ tokenService.js\n‚îú‚îÄ‚îÄ server.js\n‚îú‚îÄ‚îÄ .env\n‚îî‚îÄ‚îÄ package.json\n```\n\nOrganizing files by feature promotes modularity and maintainability.\n\n---\n\n## üë• 4. User Model and Password Hashing\n\n```js\n// models/user.js\nconst bcrypt = require('bcryptjs');\nconst users = []; // using in-memory for demo; replace with DB in production\n\nasync function createUser(username, password) {\n  const salt = await bcrypt.genSalt(12);\n  const hashed = await bcrypt.hash(password, salt);\n  const user = { id: Date.now().toString(), username, password: hashed };\n  users.push(user);\n  return user;\n}\n\nasync function findUser(username) {\n  return users.find(u => u.username === username);\n}\n\nmodule.exports = { createUser, findUser };\n```\n\n---\n\n## üöÄ 5. Token Lifecycle: Access & Refresh Tokens\n\n**tokenService.js** encapsulates token creation and validation:\n\n```js\n// utils/tokenService.js\nconst jwt = require('jsonwebtoken');\n\nfunction generateAccessToken(user) {\n  return jwt.sign({ id: user.id, username: user.username }, process.env.ACCESS_TOKEN_SECRET, { expiresIn: '15m' });\n}\n\nfunction generateRefreshToken(user) {\n  return jwt.sign({ id: user.id }, process.env.REFRESH_TOKEN_SECRET, { expiresIn: '7d' });\n}\n\nmodule.exports = { generateAccessToken, generateRefreshToken };\n```\n\nUse access tokens for API calls and refresh tokens to renew sessions securely.\n\n---\n\n## ‚úçÔ∏è 6. Auth Controller Logic\n\n```js\n// controllers/authController.js\nconst bcrypt = require('bcryptjs');\nconst { createUser, findUser } = require('../models/user');\nconst { generateAccessToken, generateRefreshToken } = require('../utils/tokenService');\nlet refreshTokens = [];\n\nasync function register(req, res) {\n  const { username, password } = req.body;\n  const user = await createUser(username, password);\n  res.status(201).json({ id: user.id, username: user.username });\n}\n\nasync function login(req, res) {\n  const { username, password } = req.body;\n  const user = await findUser(username);\n  if (!user || !(await bcrypt.compare(password, user.password))) return res.status(401).json({ message: 'Invalid credentials' });\n\n  const accessToken = generateAccessToken(user);\n  const refreshToken = generateRefreshToken(user);\n  refreshTokens.push(refreshToken);\n\n  res.json({ accessToken, refreshToken });\n}\n\nfunction token(req, res) {\n  const { token } = req.body;\n  if (!token || !refreshTokens.includes(token)) return res.sendStatus(403);\n\n  jwt.verify(token, process.env.REFRESH_TOKEN_SECRET, (err, user) => {\n    if (err) return res.sendStatus(403);\n    const newAccessToken = generateAccessToken({ id: user.id, username: user.username });\n    res.json({ accessToken: newAccessToken });\n  });\n}\n\nfunction logout(req, res) {\n  refreshTokens = refreshTokens.filter(t => t !== req.body.token);\n  res.sendStatus(204);\n}\n\nmodule.exports = { register, login, token, logout };\n```\n\n---\n\n## üõ°Ô∏è 7. Protecting Routes with Middleware\n\n```js\n// middleware/verifyToken.js\nconst jwt = require('jsonwebtoken');\n\nfunction verifyToken(req, res, next) {\n  const authHeader = req.headers['authorization'];\n  const token = authHeader?.split(' ')[1];\n  if (!token) return res.sendStatus(401);\n\n  jwt.verify(token, process.env.ACCESS_TOKEN_SECRET, (err, user) => {\n    if (err) return res.sendStatus(403);\n    req.user = user;\n    next();\n  });\n}\n\nmodule.exports = verifyToken;\n```\n\nUse middleware to ensure protected APIs only serve authenticated users.\n\n---\n\n## üìÑ 8. API Routes Definition\n\n```js\n// routes/auth.js\nconst express = require('express');\nconst router = express.Router();\nconst verifyToken = require('../middleware/verifyToken');\nconst { register, login, token, logout } = require('../controllers/authController');\n\nrouter.post('/register', register);\nrouter.post('/login', login);\nrouter.post('/token', token);\nrouter.post('/logout', logout);\nrouter.get('/protected', verifyToken, (req, res) => res.json({ message: 'Protected data', user: req.user }));\n\nmodule.exports = router;\n```\n\n---\n\n## üß™ 9. Security Best Practices\n\n- Keep secret keys in `.env`, **never commit them**\n- Use **HTTPS** to prevent token interception\n- Set **secure, HTTP-only cookies** for refresh tokens\n- Invalidate refresh tokens on logout or suspicious activity\n- Rotate secrets regularly and implement **token blacklisting** for compromised tokens\n\n---\n\n## üìä 10. Enhancements for Production-readiness\n\n- **Database persistence** for users and refresh tokens (Redis or SQL)\n- **Rate-limiting** and **IP throttling** to prevent abuse\n- **Monitoring** expired tokens and login failures\n- **Hash refresh tokens** in DB to protect against token theft\n- **Implement JWT revocation** strategies (e.g. token versioning)\n\n---\n\n## üß† Conclusion\n\nBuilding a production-grade JWT authentication system in Node.js means more than generating tokens‚Äîit‚Äôs about managing token lifecycle, securing credentials, and supporting scalable revocation strategies.\n\nBy adopting **access & refresh tokens**, **middleware enforcement**, and rigorous **security best practices**, you can build a system that is both robust and maintainable‚Äîready for enterprise-level applications.\n\n---\n\n## üîó Further Reading\n\n- [JWT Official Site](https://jwt.io/)\n- [jsonwebtoken in npm](https://www.npmjs.com/package/jsonwebtoken)\n- [OWASP Authentication Cheat Sheet](https://cheatsheetseries.owasp.org/cheatsheets/Authentication_Cheat_Sheet.html)\n- [Bcrypt Usage Patterns](https://www.npmjs.com/package/bcryptjs)\n- [Secure JWT Refresh Strategies](https://auth0.com/docs/tokens/refresh-tokens)\n",
    date: "July 2, 2025",
    readTime: "8 min read",
    image:
      "https://images.unsplash.com/photo-1526374965328-7f61d4dc18c5?ixlib=rb-4.0.3&auto=format&fit=crop&w=800&q=80",
    tags: ["Node.js", "JWT", "Authentication", "Security"],
    category: "Node.js",
  },
  {
    id: 2,
    title:
      "Architecting High-Growth React Apps: Scalable Patterns, Data Flows, and Team Workflows",
    slug: "architecting-high-growth-react-apps",
    excerpt:
      "Explore advanced architectural patterns, state management techniques, and team-centric workflows to scale React applications for high-growth environments.",
    content:
      "# Architecting High-Growth React Apps: Scalable Patterns, Data Flows, and Team Workflows\n\nAs startups evolve into high-demand web platforms, the challenges of scaling React applications multiply. Performance must stay optimal, team velocity must remain smooth, and the architecture must support evolving feature sets without collapse.\n\nThis article dives deep into proven strategies to build scalable React applications‚Äîcovering modular architecture, state orchestration, performance tuning, and developer workflows tailored for growing teams.\n\n---\n\n## üìÅ 1. Modular and Domain-Driven Architecture\n\nBreak your application into **domain-focused modules** so parallel teams can own, test, and deploy features independently.\n\n```text\nsrc/\n‚îú‚îÄ‚îÄ dashboard/\n‚îÇ   ‚îú‚îÄ‚îÄ components/\n‚îÇ   ‚îú‚îÄ‚îÄ services/\n‚îÇ   ‚îî‚îÄ‚îÄ dashboardSlice.ts\n‚îú‚îÄ‚îÄ settings/\n‚îÇ   ‚îú‚îÄ‚îÄ components/\n‚îÇ   ‚îî‚îÄ‚îÄ hooks/\n‚îú‚îÄ‚îÄ common/\n‚îÇ   ‚îú‚îÄ‚îÄ ui/\n‚îÇ   ‚îú‚îÄ‚îÄ utils/\n‚îÇ   ‚îî‚îÄ‚îÄ types/\n‚îî‚îÄ‚îÄ app/\n    ‚îú‚îÄ‚îÄ routes.tsx\n    ‚îú‚îÄ‚îÄ store.ts\n    ‚îî‚îÄ‚îÄ App.tsx\n```\n\nDomain modules encapsulate everything needed‚Äîcomponents, API services, state slices, and styles‚Äîimproving encapsulation and reducing cross-team friction.\n\n---\n\n## ‚ö° 2. Smart State Orchestration\n\nDivide state handling into three layers:\n\n- **Local (`useState`, `useReducer`)** for individual components\n- **Shared UI (`React.Context`)** for theme, notifications, and modals\n- **Global / Data Fetching** using **Zustand**, **Redux Toolkit**, or **React Query**\n\n```ts\nimport { create } from 'zustand';\n\nexport const useUserStore = create((set) => ({\n  profile: null,\n  fetchProfile: async (id) => set({ profile: await api.getProfile(id) }),\n}));\n```\n\nUse state boundaries to prevent prop drilling, simplify testing, and optimize re-renders.\n\n---\n\n## üß© 3. Decoupled Data and API Management\n\nMove all API calls into a `services/` layer and connect them via custom hooks:\n\n```ts\n// services/auth.ts\nexport const login = (creds) => api.post('/auth', creds);\n\n// hooks/useLogin.ts\nexport const useLogin = () => {\n  const mutation = useMutation(login);\n  return mutation;\n};\n```\n\nThis decoupling improves testability and enables clean, observable error handling and retries.\n\n---\n\n## üõ† 4. Performance Patterns and Code Splitting\n\n### Lazy-load curved structural modules:\n```tsx\nconst Dashboard = React.lazy(() => import('@/dashboard/Dashboard'));\n```\n\n### Memoize heavy components:\n```tsx\nconst MemoRow = React.memo(Row);\n```\n\n### Virtualize lists in high-cardinality UI:\nUse libraries like `react-window` or `react-virtualized` to reduce DOM overhead.\n\n### Batch updates and throttle user actions to minimize re-renders.\n\n---\n\n## üß™ 5. Testing Strategy for Scalable Apps\n\nAdopt a multi-layer testing strategy:\n- **Unit tests**: Test logic in isolation (hooks, utils)\n- **Component tests**: Use React Testing Library for rendering tests\n- **Integration tests**: Test feature-level flows with mocks\n- **E2E tests**: Use Playwright or Cypress for critical user journeys\n\n```ts\ntest('Login grants access', async () => {\n  render(<LoginPage />);\n  fireEvent.type(email, 'test@example.com');\n  fireEvent.click(submit);\n  expect(await screen.findByText('Dashboard')).toBeInTheDocument();\n});\n```\n\nA layered approach ensures reliability without excessive maintenance.\n\n---\n\n## üöÄ 6. CI/CD, Linting, and Developer Workflow\n\nSetup essential dev pipelines:\n- **ESLint + Prettier** with lint-staged and Husky\n- **Type-checking** in CI with `tsc --noEmit`\n- **GitHub Actions** to automate builds, tests, and deployments\n\nExample snippet:\n```yaml\njobs:\n  build:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - run: npm ci\n      - run: npm run lint\n      - run: npm test\n      - run: npm run build\n```\n\nThis ensures consistent code quality and deploy hygiene.\n\n---\n\n## üîé 7. Observability and Dev Feedback Loop\n\n- **Error tracking** with Sentry or LogRocket\n- **Performance monitoring** using Web Vitals and React Profiler\n- **Session logs** and user behavior analysis\n\nInstall Metrics:\n```js\nimport { getCLS, getFID } from 'web-vitals';\ngetCLS(console.log);\ngetFID(console.log);\n```\n\nData-backed insights drive faster bug resolution and informed performance tuning.\n\n---\n\n## üß† Final Thoughts\n\nScaling a React application isn‚Äôt about chance‚Äîit‚Äôs about **intentional structure, optimized data flows, performance guardrails, and developer-centric workflows**.\n\nKey principles to adopt today:\n- Organize by domain\n- Segment state smartly\n- Decouple data and presentation\n- Optimize performance from day one\n- Automate quality and deployment\n- Monitor true user impact\n\nBy architecting proactively, you‚Äôre ensuring your React apps can adapt, grow, and remain maintainable for the long haul.\n\n---\n\n## üîó Recommended Resources\n\n- **React Query / TanStack Query**\n- **Zustand**\n- **React Profiler & Web Vitals**\n- **Playwright for E2E Testing**\n- **Storybook Design System**\n\n---",
    date: "July 2, 2025",
    readTime: "12 min read",
    image:
      "https://images.unsplash.com/photo-1633356122102-3fe601e05bd2?ixlib=rb-4.0.3&auto=format&fit=crop&w=800&q=80",
    tags: [
      "React",
      "Scalable Architecture",
      "State Management",
      "Performance",
      "Developer Workflows",
    ],
    category: "React",
  },
  {
    id: 3,
    title:
      "Database Optimization Techniques in SQL and NoSQL (PostgreSQL vs MongoDB)",
    slug: "database-optimization-techniques",
    excerpt:
      "Master performance tuning in PostgreSQL and MongoDB with practical strategies for indexing, query optimization, schema design, and resource management.",
    content:
      '# Database Optimization Techniques in SQL and NoSQL (PostgreSQL vs MongoDB)\n\nDatabase performance is a cornerstone of application scalability and reliability. Whether you\'re working with a **relational database like PostgreSQL** or a **document-based NoSQL database like MongoDB**, understanding how to optimize for performance is essential for high-throughput systems.\n\nIn this guide, we‚Äôll explore **core optimization principles**, and compare how to apply them in **PostgreSQL (SQL)** and **MongoDB (NoSQL)** environments.\n\n---\n\n## ‚öôÔ∏è General Principles of Database Optimization\n\nBefore diving into specific engines, it\'s important to understand the common performance pillars:\n\n1. **Efficient indexing**\n2. **Query optimization**\n3. **Schema design**\n4. **Caching**\n5. **Connection management**\n6. **Resource allocation** (e.g., CPU, IOPS)\n\n---\n\n## üêò PostgreSQL Optimization Techniques (SQL)\n\nPostgreSQL is a powerful open-source relational database known for compliance, indexing, and performance capabilities.\n\n### üîç 1. Indexing Strategies\n\n- **B-Tree Index** (default): Best for equality and range queries\n- **GIN Index**: Full-text search and array containment\n- **BRIN Index**: For large, append-only tables with sequential data\n\n```sql\n-- Create GIN index for tags array\nCREATE INDEX idx_tags ON articles USING GIN (tags);\n```\n\n> ‚úÖ Use `EXPLAIN ANALYZE` to validate index usage.\n\n### üìà 2. Query Planning & Analysis\n\n- Always run `EXPLAIN ANALYZE` to understand query execution plans.\n- Watch for **sequential scans**, **nested loops**, and **sorts** on large datasets.\n\n```sql\nEXPLAIN ANALYZE SELECT * FROM users WHERE email = \'example@test.com\';\n```\n\n> üö® Optimize `JOIN` operations by indexing foreign keys and minimizing large intermediate result sets.\n\n### üß± 3. Schema Normalization vs Denormalization\n\n- Normalize for **write efficiency and consistency**\n- Denormalize (with care) for **read-heavy** use cases like analytics\n\n```sql\n-- Avoid N+1 queries with JOINs or data aggregation views\nSELECT orders.id, users.name FROM orders JOIN users ON orders.user_id = users.id;\n```\n\n### üß∞ 4. Connection & Resource Tuning\n\n- Use **connection pooling** (e.g., PgBouncer)\n- Adjust config: `work_mem`, `shared_buffers`, `effective_cache_size`\n\n```bash\n# postgresql.conf\nwork_mem = 16MB\nshared_buffers = 25% of total RAM\n```\n\n### üì¶ 5. Partitioning for Large Tables\n\n- Use **table partitioning** to split large datasets into logical parts\n\n```sql\nCREATE TABLE logs (\n  id SERIAL,\n  log_date DATE,\n  message TEXT\n) PARTITION BY RANGE (log_date);\n```\n\n---\n\n## üçÉ MongoDB Optimization Techniques (NoSQL)\n\nMongoDB stores data as JSON-like documents (BSON), making it great for flexible schema and hierarchical data. However, performance optimization requires different strategies.\n\n### üìÅ 1. Schema Design for Read vs Write\n\n**Design for the most common query patterns**. Unlike SQL, schema is flexible but must be deliberate.\n\n- **Embed** documents when one-to-many is tightly coupled (e.g., user ‚Üí addresses)\n- **Reference** for large subcollections or many-to-many\n\n```json\n// Embedded (fast reads)\n{\n  "_id": 1,\n  "name": "Alice",\n  "addresses": [\n    { "city": "Cairo", "zip": "12345" },\n    { "city": "Giza", "zip": "54321" }\n  ]\n}\n```\n\n> ‚ö†Ô∏è Don‚Äôt embed arrays that can grow unbounded (risk of 16MB document limit).\n\n### üè∑ 2. Index Optimization\n\n- Use **compound indexes** for multi-field filters\n- Use **TTL indexes** for auto-expiring logs\n- Use **covered queries** (when index contains all queried fields)\n\n```js\n// Compound index\ncollection.createIndex({ status: 1, createdAt: -1 });\n```\n\n```js\n// TTL index\ncollection.createIndex({ "createdAt": 1 }, { expireAfterSeconds: 3600 });\n```\n\n### üîÑ 3. Aggregation Pipeline Optimization\n\n- Use `$match` early to reduce dataset size\n- Avoid `$project` or `$group` until necessary\n- Use `$facet` wisely (can be expensive)\n\n```js\ncollection.aggregate([\n  { $match: { status: "active" } },\n  { $group: { _id: "$userId", count: { $sum: 1 } } }\n]);\n```\n\n### ‚öôÔ∏è 4. Query Profiling & Explain\n\n- Use `db.collection.explain("executionStats")`\n- Monitor with MongoDB Atlas or `mongotop`, `mongostat`\n\n```js\ndb.users.find({ email: "a@b.com" }).explain("executionStats")\n```\n\n### üõ† 5. Sharding for Horizontal Scaling\n\nFor very large datasets:\n\n- Enable sharding on collections with a good **shard key**\n- Avoid low-cardinality shard keys (e.g., `status: \'active\'`)\n\n```js\nsh.enableSharding("ecommerce")\nsh.shardCollection("ecommerce.orders", { userId: 1 })\n```\n\n> üö® Sharding adds complexity‚Äîonly use for large, distributed workloads.\n\n---\n\n## üß† SQL vs NoSQL: Optimization at a Glance\n\n| Feature                     | PostgreSQL                            | MongoDB                               |\n|----------------------------|----------------------------------------|----------------------------------------|\n| Schema Design              | Normalized or denormalized             | Embedded or referenced                 |\n| Index Types                | B-Tree, GIN, BRIN                      | Single, compound, TTL, text            |\n| Joins                      | Native support                         | Manual via app logic or aggregation    |\n| Query Analysis             | `EXPLAIN ANALYZE`                      | `explain("executionStats")`           |\n| Scaling                    | Vertical, partitioning, read replicas  | Horizontal via sharding                |\n| Use Case Fit               | Complex relational data, ACID          | Flexible schema, real-time apps        |\n\n---\n\n## ‚úÖ Summary & Best Practices\n\n| Best Practice                            | PostgreSQL                          | MongoDB                               |\n|------------------------------------------|-------------------------------------|----------------------------------------|\n| Always index query filters               | ‚úÖ Yes                              | ‚úÖ Yes                                 |\n| Use `EXPLAIN` to optimize queries        | ‚úÖ Yes                              | ‚úÖ Yes                                 |\n| Avoid unnecessary data in large queries  | ‚úÖ Use projection & joins           | ‚úÖ Use projection & aggregation         |\n| Optimize for read or write heavy use     | ‚úÖ Normalize or denormalize         | ‚úÖ Embed or reference strategically     |\n| Scale out when needed                    | ‚úÖ Read replicas or partitioning    | ‚úÖ Sharding with careful key selection  |\n\n---\n\n## üîó Further Reading\n\n- [PostgreSQL Performance Tuning Guide](https://www.postgresql.org/docs/current/performance-tips.html)\n- [MongoDB Performance Best Practices](https://www.mongodb.com/docs/manual/administration/production-notes/)\n- [Use Indexes Effectively in MongoDB](https://www.mongodb.com/docs/manual/indexes/)\n- [EXPLAIN in PostgreSQL](https://www.postgresql.org/docs/current/using-explain.html)\n- [Sharding in MongoDB](https://www.mongodb.com/docs/manual/sharding/)\n',
    date: "March 25, 2024",
    readTime: "12 min read",
    image:
      "https://images.unsplash.com/photo-1555066931-4365d14bab8c?ixlib=rb-4.0.3&auto=format&fit=crop&w=800&q=80",
    tags: ["Database", "PostgreSQL", "MongoDB", "Optimization", "Performance"],
    category: "Databases",
  },
  {
    id: 4,
    title: "Building Real-Time Applications with Socket.io",
    slug: "real-time-applications-with-socketio",
    excerpt:
      "Learn how to build scalable, real-time web applications using Socket.io. We cover setup, core concepts, and best practices for delivering interactive user experiences.",
    content:
      "# Building Real-Time Applications with Socket.io\n\nReal-time web applications are becoming essential in modern software ‚Äî from messaging platforms to collaborative tools, live dashboards, multiplayer games, and beyond. At the heart of many of these systems is **Socket.io**, a powerful JavaScript library that enables bi-directional, event-based communication between the browser and the server.\n\nIn this article, we'll explore the core features of Socket.io, its setup in a Node.js environment, and how to build real-time functionality into your applications.\n\n---\n\n## üöÄ What is Socket.io?\n\n**Socket.io** is a JavaScript library for real-time web applications. It enables **real-time, bidirectional, event-based communication** between clients and servers using **WebSockets** or **fallback HTTP long polling** when necessary.\n\nKey benefits include:\n\n- Cross-browser support\n- Automatic reconnection\n- Multiplexing support\n- Room and namespace abstraction\n- Middleware support on both client and server\n\n---\n\n## üß± How Does Socket.io Work?\n\nSocket.io consists of two parts:\n\n- **Server-side library** (Node.js)\n- **Client-side library** (browser)\n\nIt abstracts WebSocket protocols and handles connection fallbacks automatically.\n\nThe basic communication looks like this:\n\n```txt\nClient ‚ÜîÔ∏è Server (via WebSocket)\n```\n\nWhen WebSocket isn‚Äôt available, it transparently falls back to HTTP long polling.\n\n---\n\n## üì¶ Installation\n\nInstall both server and client libraries:\n\n```bash\nnpm install socket.io\nnpm install socket.io-client\n```\n\n---\n\n## ‚úçÔ∏è Basic Server Setup\n\n```js\n// server.js\nconst express = require('express');\nconst http = require('http');\nconst { Server } = require('socket.io');\n\nconst app = express();\nconst server = http.createServer(app);\nconst io = new Server(server);\n\nio.on('connection', (socket) => {\n  console.log('User connected:', socket.id);\n\n  socket.on('message', (data) => {\n    console.log('Received:', data);\n    io.emit('message', data); // Broadcast to all\n  });\n\n  socket.on('disconnect', () => {\n    console.log('User disconnected:', socket.id);\n  });\n});\n\nserver.listen(3000, () => console.log('Server running on http://localhost:3000'));\n```\n\n---\n\n## üßë‚Äçüíª Client Setup\n\n```html\n<!-- index.html -->\n<!DOCTYPE html>\n<html>\n<head><title>Socket.io Chat</title></head>\n<body>\n  <input id=\"msgInput\" />\n  <button onclick=\"sendMessage()\">Send</button>\n  <ul id=\"messages\"></ul>\n\n  <script src=\"/socket.io/socket.io.js\"></script>\n  <script>\n    const socket = io();\n\n    socket.on('message', (data) => {\n      const li = document.createElement('li');\n      li.innerText = data;\n      document.getElementById('messages').appendChild(li);\n    });\n\n    function sendMessage() {\n      const msg = document.getElementById('msgInput').value;\n      socket.emit('message', msg);\n    }\n  </script>\n</body>\n</html>\n```\n\n---\n\n## üß© Key Concepts\n\n### üîÑ Events\n- Custom event types can be defined (`'chat'`, `'typing'`, etc.)\n- Use `socket.emit()` to send and `socket.on()` to receive\n\n### üè† Rooms\nLet users join rooms to segment communication:\n\n```js\nsocket.join('room1');\nio.to('room1').emit('message', 'Welcome to room1');\n```\n\n### üß† Namespaces\nLogical separation of sockets:\n\n```js\nconst adminNamespace = io.of('/admin');\nadminNamespace.on('connection', socket => {\n  console.log('Admin connected');\n});\n```\n\n### üîê Authentication\nPass tokens during connection:\n\n```js\nconst socket = io({\n  auth: { token: 'your_token_here' }\n});\n```\n\nOn the server:\n```js\nio.use((socket, next) => {\n  const token = socket.handshake.auth.token;\n  if (isValid(token)) next();\n  else next(new Error('Unauthorized'));\n});\n```\n\n---\n\n## üß™ Best Practices\n\n- **Use middleware** for auth and validation\n- **Handle reconnections** and edge cases\n- **Avoid memory leaks** ‚Äî always clean up listeners\n- **Use rooms** for scalability\n- **Throttle events** to prevent abuse\n\n---\n\n## üß† Conclusion\n\nSocket.io makes it easy to integrate real-time features in modern web applications. Whether you're building chat apps, games, or live dashboards, it provides the tools to manage connections, broadcast events, and scale efficiently.\n\nWith its fallback support and developer-friendly API, it's a great choice for real-time functionality in full-stack JavaScript projects.\n\n---\n\n## üîó Further Reading\n\n- [Socket.io Documentation](https://socket.io/docs/)\n- [Scaling Socket.io with Redis](https://socket.io/docs/v4/using-multiple-nodes/)\n- [WebSockets vs Socket.io](https://ably.com/blog/websockets-vs-socket-io)\n- [Real-Time Node.js Architecture](https://nodejs.org/en/learn/)\n",
    date: "March 18, 2024",
    readTime: "10 min read",
    image:
      "https://images.unsplash.com/photo-1551033406-611cf9a28f67?ixlib=rb-4.0.3&auto=format&fit=crop&w=800&q=80",
    tags: ["Real-Time", "Socket.io", "Node.js", "WebSockets"],
    category: "WebSockets",
  },
  {
    id: 5,
    title: "Microservices vs Monoliths: Choosing the Right Architecture",
    slug: "microservices-vs-monoliths",
    excerpt:
      "Understand the trade-offs between monolithic and microservices architectures. Learn when to use each, their pros and cons, and how to make an informed architectural decision for your team.",
    content:
      "# Microservices vs Monoliths: Choosing the Right Architecture\n\nChoosing the right architectural pattern for your application is a critical decision that impacts development speed, scalability, and long-term maintainability. Two primary models dominate the landscape: **monoliths** and **microservices**.\n\nIn this article, we‚Äôll explore both architectures, compare their strengths and weaknesses, and guide you on when and why to choose one over the other.\n\n---\n\n## üß± What is a Monolith?\n\nA **monolithic architecture** is a single unified codebase where all application logic ‚Äî including UI, business logic, and data access ‚Äî is bundled and deployed together.\n\n### ‚úÖ Benefits of Monoliths\n- **Simplicity**: Easier to build, test, and deploy initially\n- **Less operational overhead**: Single codebase and process\n- **Faster initial development**: Especially for small teams and MVPs\n\n### ‚ùå Drawbacks\n- **Scalability bottlenecks**: You must scale the whole app, even if only one part needs it\n- **Tight coupling**: Code becomes interdependent over time, slowing development\n- **Long deployment cycles**: A change in one area requires full redeployment\n\n---\n\n## üß© What are Microservices?\n\nA **microservices architecture** breaks down the application into small, independent services that communicate over a network (typically via HTTP or message queues).\n\nEach service:\n- Has a single, focused responsibility (e.g., user, billing, notifications)\n- Is developed, tested, deployed, and scaled independently\n- Often has its own database (polyglot persistence)\n\n### ‚úÖ Benefits of Microservices\n- **Independent scalability**: Scale services individually based on demand\n- **Team autonomy**: Teams own specific services with independent deployment pipelines\n- **Improved fault isolation**: A failure in one service doesn‚Äôt crash the whole system\n- **Technology flexibility**: Each service can use different languages, frameworks, or databases\n\n### ‚ùå Drawbacks\n- **Complexity**: Requires orchestration, service discovery, logging, monitoring, etc.\n- **Distributed system challenges**: Network latency, retries, eventual consistency\n- **DevOps overhead**: CI/CD pipelines, deployment scripts, and infrastructure multiply\n\n---\n\n## ‚öñÔ∏è Key Differences\n\n| Feature                    | Monolith                            | Microservices                       |\n|---------------------------|--------------------------------------|-------------------------------------|\n| Deployment               | Single unit                          | Independently deployable services   |\n| Scalability              | Whole app                           | Per service                         |\n| Fault Isolation          | Low                                  | High                                |\n| DevOps Complexity        | Low                                  | High                                |\n| Onboarding               | Simple (one codebase)               | Complex (multiple repos/services)   |\n| Best for                 | Small teams, MVPs, internal tools   | Large apps, distributed teams       |\n\n---\n\n## üß† When to Choose What?\n\n### ‚úÖ Choose **Monolith** if:\n- You‚Äôre building an MVP or prototype\n- You have a small team\n- Speed of delivery is more important than flexibility\n- Operational overhead must be minimal\n\n### ‚úÖ Choose **Microservices** if:\n- Your app is growing in complexity and scale\n- You need to scale components independently\n- You have multiple teams working in parallel\n- You want to adopt CI/CD and DevOps culture\n\n> ‚ö†Ô∏è Don‚Äôt start with microservices unless you absolutely need them. Many teams **prematurely over-engineer** and end up with operational complexity that outweighs the benefits.\n\n---\n\n## üß™ Migration Strategy: Monolith ‚ûú Microservices\n\nMany companies start with a monolith and **gradually refactor** into microservices:\n\n1. **Modularize your monolith** (e.g., domain-based folders/modules)\n2. Extract well-defined, low-coupled modules into services\n3. Build infrastructure: API gateway, service discovery, observability, etc.\n4. Move incrementally ‚Äî one service at a time\n\n---\n\n## üõ† Tools and Ecosystem\n\n- **API Gateways**: Kong, NGINX, AWS API Gateway\n- **Service Communication**: gRPC, REST, Message Queues (Kafka, RabbitMQ)\n- **Containerization**: Docker\n- **Orchestration**: Kubernetes, Docker Swarm\n- **Monitoring & Logging**: Prometheus, Grafana, ELK Stack, Jaeger\n\n---\n\n## üß† Conclusion\n\nThere is no one-size-fits-all architecture. Your choice between **monoliths and microservices** should be guided by:\n\n- Team size and structure\n- Application complexity and growth expectations\n- Operational maturity and infrastructure capabilities\n\nStart simple. **Evolve your architecture based on real needs** rather than trends.\n\n---\n\n## üîó Further Reading\n\n- [Martin Fowler on Microservices](https://martinfowler.com/articles/microservices.html)\n- [12 Factor App Principles](https://12factor.net/)\n- [MonolithFirst by ThoughtWorks](https://www.thoughtworks.com/insights/blog/microservices-prerequisite)\n- [Building Microservices by Sam Newman](https://www.oreilly.com/library/view/building-microservices/9781491950340/)\n- [AWS Microservices Guide](https://aws.amazon.com/microservices/)\n",
    date: "March 20, 2024",
    readTime: "9 min read",
    image:
      "https://images.unsplash.com/photo-1517842645767-c639042777db?ixlib=rb-4.0.3&auto=format&fit=crop&w=800&q=80",
    tags: ["Architecture", "Microservices", "Monolith", "Software Design"],
    category: "Architecture",
  },
  {
    id: 6,
    title: "Advanced TypeScript Patterns for React Developers",
    slug: "advanced-typescript-patterns-for-react",
    excerpt:
      "Level up your React applications with advanced TypeScript techniques, including discriminated unions, mapped types, polymorphic components, and type-safe component patterns.",
    content:
      "# Advanced TypeScript Patterns for React Developers\n\nTypeScript is a powerful addition to the React ecosystem, offering static type safety and improved developer experience. But beyond basic props typing, TypeScript can be leveraged in advanced ways to make your React codebase more robust, scalable, and maintainable.\n\nIn this article, we‚Äôll explore advanced TypeScript patterns and techniques tailored specifically for React developers.\n\n---\n\n## ‚öôÔ∏è 1. Discriminated Unions for Conditional Props\n\nDiscriminated unions are perfect for components that have mutually exclusive props.\n\n```tsx\ntype ButtonProps =\n  | { variant: 'icon'; icon: React.ReactNode; label?: never }\n  | { variant: 'text'; label: string; icon?: never };\n\nconst Button: React.FC<ButtonProps> = (props) => {\n  if (props.variant === 'icon') {\n    return <button>{props.icon}</button>;\n  }\n  return <button>{props.label}</button>;\n};\n```\n\n### ‚úÖ Why it works:\n- Enforces **mutual exclusivity** at compile time\n- Prevents accidental misuse of props\n\n---\n\n## üîÅ 2. Mapped Types for Form Components\n\nUse mapped types to create **strongly-typed form handlers** based on a data model.\n\n```ts\ntype FormData = {\n  name: string;\n  age: number;\n};\n\nconst [form, setForm] = useState<FormData>({ name: '', age: 0 });\n\nfunction handleChange<K extends keyof FormData>(key: K, value: FormData[K]) {\n  setForm(prev => ({ ...prev, [key]: value }));\n}\n```\n\n### üîê Benefits:\n- Type-safe access to keys and values\n- Helps prevent mismatched types in form updates\n\n---\n\n## üß† 3. Polymorphic Components with Generics\n\nCreate reusable components that can render as different HTML elements using the `as` prop.\n\n```tsx\ntype PolymorphicProps<E extends React.ElementType> = {\n  as?: E;\n  children: React.ReactNode;\n} & React.ComponentPropsWithoutRef<E>;\n\nconst Box = <E extends React.ElementType = 'div'>({ as, children, ...rest }: PolymorphicProps<E>) => {\n  const Component = as || 'div';\n  return <Component {...rest}>{children}</Component>;\n};\n\n<Box as=\"a\" href=\"#\">Link Box</Box>\n```\n\n### üß∞ Use cases:\n- Buttons, links, headings with dynamic tags\n- Reduces component duplication\n\n---\n\n## üß¨ 4. Type-Safe Context APIs\n\nAvoid `any` in context by creating a properly typed context API.\n\n```ts\ntype ThemeContextType = {\n  theme: 'light' | 'dark';\n  toggleTheme: () => void;\n};\n\nconst ThemeContext = React.createContext<ThemeContextType | undefined>(undefined);\n\nexport const useTheme = () => {\n  const ctx = useContext(ThemeContext);\n  if (!ctx) throw new Error('useTheme must be used within a ThemeProvider');\n  return ctx;\n};\n```\n\n### üîê Why it matters:\n- Prevents `undefined` access errors\n- Helps IDEs provide better autocomplete\n\n---\n\n## üß∞ 5. Utility Types for Prop Management\n\nUse built-in and custom utility types to manage props across components.\n\n### Example: `Omit`\n\n```ts\ntype InputProps = React.InputHTMLAttributes<HTMLInputElement>;\n\ntype CustomInputProps = Omit<InputProps, 'onChange'> & {\n  onChange: (value: string) => void;\n};\n\nconst Input: React.FC<CustomInputProps> = ({ onChange, ...rest }) => {\n  return <input {...rest} onChange={(e) => onChange(e.target.value)} />;\n};\n```\n\n### üß© Other useful types:\n- `Pick<T, K>`\n- `Partial<T>`\n- `Required<T>`\n- `Record<K, T>`\n\n---\n\n## üì¶ Bonus: Prop Inference with `React.ComponentProps`\n\nUse component prop types without duplication:\n\n```ts\ntype ButtonProps = React.ComponentProps<'button'> & {\n  variant?: 'primary' | 'secondary';\n};\n\nconst Button: React.FC<ButtonProps> = ({ variant = 'primary', ...rest }) => {\n  return <button className={`btn-${variant}`} {...rest} />;\n};\n```\n\n### ‚úÖ Why it helps:\n- Ensures native props stay in sync\n- Eliminates redundant typing\n\n---\n\n## üß† Conclusion\n\nAdvanced TypeScript patterns elevate your React codebase by increasing **type safety**, **reusability**, and **developer confidence**.\n\nBy embracing these techniques:\n- You'll reduce bugs before runtime\n- Improve collaboration across teams\n- Make your components more scalable and maintainable\n\n---\n\n## üîó Further Reading\n\n- [React TypeScript Cheatsheet](https://react-typescript-cheatsheet.netlify.app/)\n- [TypeScript Utility Types](https://www.typescriptlang.org/docs/handbook/utility-types.html)\n- [Effective TypeScript](https://www.oreilly.com/library/view/effective-typescript/9781492053736/)\n- [Polymorphic Components in TypeScript](https://blog.logrocket.com/building-polymorphic-components-react-typescript/)",
    date: "March 22, 2024",
    readTime: "10 min read",
    image:
      "https://images.unsplash.com/photo-1593720213428-28a5b9e94613?ixlib=rb-4.0.3&auto=format&fit=crop&w=800&q=80",
    tags: ["TypeScript", "React", "Advanced Patterns", "Component Design"],
    category: "React",
  },
];

// Function to load markdown content dynamically
const loadMarkdownContent = async (slug: string): Promise<string> => {
  try {
    const response = await fetch(`/src/content/${slug}.md`);
    if (response.ok) {
      return await response.text();
    }
  } catch (error) {
    console.error(`Failed to load content for ${slug}:`, error);
  }

  // Fallback to inline content
  const post = blogPosts.find((p) => p.slug === slug);
  return post?.content ?? "";
};

export const getAllBlogPosts = (): BlogPost[] => {
  return blogPosts;
};

export const getBlogPostBySlug = async (
  slug: string
): Promise<BlogPost | null> => {
  const post = blogPosts.find((p) => p.slug === slug);
  if (!post) return null;

  // Load markdown content if not already loaded
  if (!post.content) {
    post.content = await loadMarkdownContent(slug);
  }
  return post;
};

export const getRelatedPosts = (currentSlug: string): BlogPost[] => {
  const currentPost = blogPosts.find((p) => p.slug === currentSlug);
  if (!currentPost) return [];

  return blogPosts
    .filter(
      (post) =>
        post.slug !== currentSlug &&
        post.tags.some((tag) => currentPost.tags.includes(tag))
    )
    .slice(0, 2);
};

export const searchBlogPosts = (query: string): BlogPost[] => {
  const lowercaseQuery = query.toLowerCase();
  return blogPosts.filter(
    (post) =>
      post.title.toLowerCase().includes(lowercaseQuery) ||
      post.excerpt.toLowerCase().includes(lowercaseQuery) ||
      post.tags.some((tag) => tag.toLowerCase().includes(lowercaseQuery))
  );
};

export const filterBlogPostsByCategory = (category: string): BlogPost[] => {
  if (category === "All") return blogPosts;
  return blogPosts.filter(
    (post) =>
      post.category === category ||
      post.tags.some((tag) =>
        tag.toLowerCase().includes(category.toLowerCase())
      )
  );
};
